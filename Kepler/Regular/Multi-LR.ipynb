{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-a151b39c-c9e0-4cf9-b1a3-9643935f87c3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168366499,
    "source_hash": "cc523c23",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#normalize X values to help model converge\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data = (data - mean) / std\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieve and format data - into labels and examples from the dataset\n",
    "def features_and_labels(filename_a, filename_b):\n",
    "    with open(filename_b, 'rb') as f:\n",
    "        labels = np.load(f).transpose()\n",
    "    \n",
    "    data = pd.read_pickle(filename_a)\n",
    "    #https://stackoverflow.com/questions/22798934/pandas-long-to-wide-reshape-by-two-variables\n",
    "    data_x = data.pivot(index='id', columns='time', values='FLUX')\n",
    "    data_x = normalize(data_x)\n",
    "    data_x = data_x.transpose()\n",
    "    data_x = data_x.to_numpy()\n",
    "    return data_x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 12589) (1, 12589)\n"
     ]
    }
   ],
   "source": [
    "training_data_x, training_data_y = features_and_labels(\"../Kepler-Train.pkl\", \"../Labels-Train.npy\")\n",
    "print(training_data_x.shape, training_data_y.shape)\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 07:51:37.141000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.148393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.148724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.149644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-15 07:51:37.150811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.151339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.151802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.653437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.653974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.654423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 07:51:37.654830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 241 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Training error= 0.086543135 Weights= [[ 3.7879896e-04  1.8589903e-04  2.8455781e-04  1.7257247e-04\n",
      "   1.4180588e-05 -1.6046110e-04 -4.5067412e-04 -4.3503122e-04\n",
      "  -5.1769969e-04 -6.2773179e-04 -7.9175056e-04 -1.0526601e-03\n",
      "  -1.0928960e-03 -1.1384054e-03 -1.0729275e-03 -1.1507128e-03\n",
      "  -1.2510265e-03 -1.2776119e-03 -1.2895445e-03 -1.2053946e-03\n",
      "  -1.1490255e-03 -1.1921276e-03 -1.2573759e-03 -1.0964414e-03\n",
      "  -1.2391945e-03 -1.4589423e-03 -1.5019424e-03 -1.4921605e-03\n",
      "  -1.2903677e-03 -9.9651492e-04 -7.9815334e-04 -8.3247176e-04\n",
      "  -8.1751047e-04 -7.9680525e-04 -6.6964567e-04 -4.7571145e-04\n",
      "  -4.6622436e-04 -5.4712920e-04 -6.1554811e-04 -6.4099679e-04\n",
      "  -7.3306699e-04 -6.4235152e-04 -8.2443649e-04 -7.0345268e-04\n",
      "  -5.3181069e-04 -5.9546588e-04 -7.7271002e-04 -9.5215003e-04\n",
      "  -1.0682377e-03 -1.3501599e-03 -1.4542186e-03 -1.6000009e-03\n",
      "  -1.8780994e-03 -2.0361675e-03 -1.8683107e-03 -1.9301062e-03\n",
      "  -2.0855537e-03 -2.2938803e-03 -2.5902796e-03 -2.1512210e-03\n",
      "  -2.7202191e-03 -2.8999110e-03 -3.1183762e-03 -3.2955930e-03\n",
      "  -1.6018220e-03 -3.9709802e-03 -3.2373585e-03 -3.2644777e-03\n",
      "  -3.5776864e-03 -2.8374542e-03 -3.5575295e-03 -2.9422657e-03\n",
      "  -2.5993634e-03 -2.2501552e-03 -1.8012462e-03 -1.9788456e-03\n",
      "  -1.2290422e-03 -8.2030712e-04  1.8795219e-04  1.4479997e-03\n",
      "   2.5132084e-03  3.6492378e-03  4.8645586e-03  6.2058470e-03\n",
      "   7.4749584e-03  7.9976069e-03  7.3953890e-03  4.6091611e-03\n",
      "  -5.8771588e-04 -6.0580126e-03 -9.7791255e-03 -1.1235148e-02\n",
      "  -1.1271483e-02 -1.0890741e-02 -9.9776359e-03 -9.0449937e-03\n",
      "  -8.2041454e-03 -7.3347045e-03 -6.8527102e-03 -6.7955600e-03\n",
      "  -6.5978044e-03 -6.7904196e-03 -7.0213298e-03 -7.3387846e-03\n",
      "  -8.0230338e-03 -8.5293651e-03 -9.2976196e-03 -9.8345736e-03\n",
      "  -1.0310285e-02 -1.0388918e-02 -9.2628328e-03 -5.6656264e-03\n",
      "  -3.7917463e-04  4.3271696e-03  6.7807101e-03  7.2483625e-03\n",
      "   5.8017015e-03  5.6289705e-03  4.5601046e-03  3.5572986e-03\n",
      "   2.7035889e-03  1.6053696e-03  9.9119195e-04  3.1504323e-04\n",
      "  -3.1222746e-04 -7.0713845e-04 -1.3527699e-03 -1.3294573e-03\n",
      "  -1.0119402e-03 -1.9310132e-03 -1.9440546e-03 -2.8670302e-03\n",
      "  -2.4766466e-03 -1.9765561e-03 -2.7852762e-03 -2.4814378e-03\n",
      "  -3.0521201e-03 -2.5144906e-03 -2.1493400e-03 -2.1540634e-03\n",
      "  -2.2770036e-03 -2.4153800e-03 -1.4058789e-03 -1.5499063e-03\n",
      "  -1.7050846e-03 -1.4460172e-03 -1.6889052e-03 -1.4791730e-03\n",
      "  -1.2997412e-03 -1.1839595e-03 -1.0749263e-03 -1.0001623e-03\n",
      "  -8.5168495e-04 -7.3914207e-04 -7.1929413e-04 -6.9087115e-04\n",
      "  -7.0891267e-04 -6.5861881e-04 -5.4582936e-04 -6.7659281e-04\n",
      "  -6.5328396e-04 -8.4386946e-04 -6.9347781e-04 -6.5315753e-04\n",
      "  -5.7666085e-04 -5.8574992e-04 -7.5349997e-04 -9.0058421e-04\n",
      "  -8.3679205e-04 -9.4170286e-04 -1.1642363e-03 -1.0866950e-03\n",
      "  -1.1512584e-03 -1.3658565e-03 -1.2669420e-03 -1.2701097e-03\n",
      "  -1.2456162e-03 -1.1497728e-03 -1.3184220e-03 -1.4390158e-03\n",
      "  -1.4306911e-03 -1.5509290e-03 -1.5048470e-03 -1.2152621e-03\n",
      "  -1.2693491e-03 -1.2391831e-03 -1.1479743e-03 -1.1987311e-03\n",
      "  -1.0796537e-03 -7.4264250e-04 -6.6998997e-04 -3.6619656e-04\n",
      "  -1.2981487e-04 -4.1751994e-04 -2.5535084e-04 -4.3149438e-04\n",
      "  -4.8695470e-04 -1.6680956e-04 -2.0463268e-04  9.4432064e-05\n",
      "   1.7090903e-04]] Bias= [0.03197687] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "    \n",
    "    loss_arr.append(current_loss)\n",
    "    acc_arr.append(accuracy(logistic_layer(np.dot(current_W,training_data_x) + current_b), training_data_y))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"Weights=\", session.run(W), \"Bias=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage:  59.40279542566709 %\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = features_and_labels(\"../Kepler-Test.pkl\", \"../Labels-Test.npy\")\n",
    "\n",
    "predicted_y = np.dot(session.run(W), test_x) + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))\n",
    "    np.save(f, loss_arr)\n",
    "    np.save(f, acc_arr)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
