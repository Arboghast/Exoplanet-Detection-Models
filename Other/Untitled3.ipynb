{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304d3536-5180-46e7-a79b-6f00a291189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from numpy import exp\n",
    "import lightkurve\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#https://stackoverflow.com/questions/60191681/cannot-load-file-containing-pickled-data-python-npy-i-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ab37e7-d8bb-46b1-9f33-199c4dc77fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tce(kepid, tce_plnt_num, filenames):\n",
    "    for filename in filenames:\n",
    "        for record in tf.compat.v1.python_io.tf_record_iterator(filename):\n",
    "            ex = tf.train.Example.FromString(record)\n",
    "            if (ex.features.feature[\"kepid\"].int64_list.value[0] == kepid and\n",
    "                ex.features.feature[\"tce_plnt_num\"].int64_list.value[0] == tce_plnt_num):\n",
    "                print(\"Found {}_{} in file {}\".format(kepid, tce_plnt_num, filename))\n",
    "                return ex\n",
    "    raise ValueError(\"{}_{} not found in files: {}\".format(kepid, tce_plnt_num, filenames))\n",
    "\n",
    "def getLocalView(kepid, dir):\n",
    "    filenames = tf.io.gfile.glob(os.path.join(dir, \"*\"))\n",
    "    assert filenames, \"No files found in {}\".format(dir)\n",
    "    ex = find_tce(kepid, 1, filenames)\n",
    "\n",
    "    # Get the local view.\n",
    "    local_view = np.array(ex.features.feature[\"local_view\"].float_list.value)\n",
    "    return local_view\n",
    "\n",
    "def downloadLC_kepler(target):\n",
    "    #search and download target light curve\n",
    "    search_result = lk.search_lightcurve(target, author='Kepler', cadence='long')\n",
    "\n",
    "    kep_id = search_result.target_name.data[0]\n",
    "    kep_id = kep_id[4:] #substr to remove \"kplr\" prefix\n",
    "    kep_id = int(kep_id.lstrip(\"0\"))\n",
    "\n",
    "    local_view = getLocalView(kep_id, \"../Kepler/TFRecords\")\n",
    "    local_view_matrix = np.expand_dims(local_view,axis=0)\n",
    "    return local_view_matrix\n",
    "\n",
    "#error handling for downloading\n",
    "def downloadLC_kaggle(target):\n",
    "    light_curve = lk.search_lightcurve(target, author='Kepler', cadence='long', quarter=3).download()\n",
    "    light_curve = light_curve.flatten().remove_outliers()\n",
    "    flux = np.array(light_curve.flux)\n",
    "    flux = np.expand_dims(flux, axis=0)\n",
    "    return flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d103a214-ead3-4d1b-98df-d91ceef6d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tobool(probs, path):\n",
    "    if(np.any(probs >= .5)): #potential bug\n",
    "        return \"true\"\n",
    "    else:\n",
    "        return \"false\"\n",
    "\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y))\n",
    "    y = y.ravel()\n",
    "    return y\n",
    "\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data = (data - mean) / std\n",
    "    return data\n",
    "\n",
    "def light_curve_to_matrix_kaggle_lightkurve(lc):\n",
    "    inputLC = downloadLC_kaggle(lc)\n",
    "    flux_copy = np.array(inputLC[0])\n",
    "    amt_pad = 3197-(len(inputLC[0])%3197)                                              #amount of medians to pad the last row of dataframe\n",
    "    flux_median = np.full(shape=amt_pad, fill_value=np.median(np.array(inputLC[0])))   #array of medians to pad the last row to reach a factor of 3197\n",
    "    flux_copy = np.append(flux_copy, flux_median)\n",
    "    final_matrix = np.reshape(flux_copy, (len(flux_copy)//3197,3197))\n",
    "    normalized_matrix = normalize(final_matrix)\n",
    "    return normalized_matrix\n",
    "\n",
    "def lightcurve_to_kaggle_tsfresh(lc):\n",
    "    matrix = pd.DataFrame({\n",
    "        \"id\" : np.zeros(len(lc), dtype=int),\n",
    "        \"time\" : list(range(0, len(lc))),\n",
    "        \"flux\" : lc})\n",
    "    \n",
    "    extracted_features = extract_features(matrix, column_id= \"id\", column_sort= \"time\", \n",
    "                                      column_value= \"flux\", \n",
    "                                      default_fc_parameters= EfficientFCParameters())\n",
    "    extracted_features.dropna(axis=1, inplace=True)  #dropped the nan column\n",
    "    normalized_matrix = preprocessing.normalize(extracted_features,norm='max', axis=0)\n",
    "    return normalized_matrix\n",
    "\n",
    "def lightcurve_to_kepler_tsfresh(lc):\n",
    "    matrix = pd.DataFrame({\n",
    "        \"id\" : np.zeros(len(lc), dtype=int),\n",
    "        \"time\" : list(range(0, len(lc))),\n",
    "        \"FLUX\" : lc})\n",
    "    \n",
    "    extracted_features = extract_features(matrix, column_id= \"id\", column_sort= \"time\", \n",
    "                                      column_value= \"FLUX\", \n",
    "                                      default_fc_parameters= EfficientFCParameters())\n",
    "    with open(\"../Kepler/TSFresh/nanlist.txt\") as file:\n",
    "        for readline in file: \n",
    "            line_strip = readline.strip()\n",
    "            extracted_features.drop(line_strip, axis=1, inplace=True)\n",
    "    normalized_matrix = preprocessing.normalize(extracted_features,norm='max', axis=0)\n",
    "    return normalized_matrix\n",
    "\n",
    "def getPredictions(inputLC, models, path):\n",
    "    inputLC_keras = np.expand_dims(inputLC, -1)\n",
    "    predictions = {}\n",
    "    \n",
    "    if \"rnn\" in models:\n",
    "        reconstructed_model = keras.models.load_model(path + \"/keras-models/KerasRNN\")\n",
    "        probability = reconstructed_model.predict(inputLC_keras)\n",
    "        predictions[\"RNN\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability, path)}\n",
    "\n",
    "    if \"lstm\" in models:\n",
    "        reconstructed_model = keras.models.load_model(path + \"/keras-models/KerasLSTM\")\n",
    "        probability = reconstructed_model.predict(inputLC_keras)\n",
    "        predictions[\"LSTM\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability, path)}\n",
    "            \n",
    "    if \"gru\" in models:\n",
    "        reconstructed_model = keras.models.load_model(path + \"/keras-models/KerasGRU\")\n",
    "        probability = reconstructed_model.predict(inputLC_keras)\n",
    "        predictions[\"GRU\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability, path)}\n",
    "\n",
    "    #Logistic Regression\n",
    "    if \"lr\" in models:\n",
    "        with open(path + \"/tf-models/multi-lr.npy\", 'rb') as f:\n",
    "            W = np.load(f)\n",
    "            b = np.load(f)\n",
    "        predicted_y = W * inputLC + b\n",
    "        predicted_y = logistic_layer(predicted_y)\n",
    "        probability = np.max(predicted_y)\n",
    "        predictions[\"LR\"] = {\"Probability\" : probability, \"Classification\" : tobool(np.array(predicted_y), path)}\n",
    "\n",
    "            \n",
    "    #Decision Tree & Random Forest\n",
    "    if \"rf\" in models:\n",
    "        with open(path + \"/tf-models/decision-tree.pkl\", 'rb') as f:\n",
    "            dt = pickle.load(f)\n",
    "        probability = dt.predict_proba(inputLC)\n",
    "        predictions[\"DT\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability, path)}\n",
    "\n",
    "        with open(path + \"/tf-models/random-forest.pkl\", 'rb') as f:\n",
    "            rf = pickle.load(f)\n",
    "        probability = rf.predict_proba(inputLC)\n",
    "        predictions[\"RF\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability, path)}\n",
    "    \n",
    "    return predictions\n",
    "                \n",
    "def predict(target_name, training_data, processing, models):\n",
    "    \n",
    "    if training_data == \"kaggle\" and processing == \"tsfresh\":\n",
    "            inputLC = downloadLC_kaggle(target_name)[0]\n",
    "            inputLC_kaggle_tsfresh = lightcurve_to_kaggle_tsfresh(inputLC)\n",
    "            return getPredictions(inputLC_kaggle_tsfresh, models, \"../Kaggle/TSFresh\")\n",
    "                \n",
    "    if training_data == \"kaggle\" and processing == \"lightkurve\":\n",
    "            inputLC_kaggle_lightkurve = light_curve_to_matrix_kaggle_lightkurve(target_name)\n",
    "            return getPredictions(inputLC_kaggle_lightkurve, models, \"../Kaggle/Regular\")\n",
    "    \n",
    "    if training_data == \"kepler\" and processing == \"tsfresh\":\n",
    "            inputLC = downloadLC_kepler(target_name)[0]\n",
    "            inputLC_kepler_tsfresh = lightcurve_to_kepler_tsfresh(inputLC)\n",
    "            return getPredictions(inputLC_kepler_tsfresh, models, \"../Kepler/TSFresh\")\n",
    "        \n",
    "    if training_data == \"kepler\" and processing == \"lightkurve\":\n",
    "            inputLC_kepler_lightkurve = downloadLC_kepler(target_name)\n",
    "            return getPredictions(inputLC_kepler_lightkurve, models, \"../Kepler/Regular\")    \n",
    "    \n",
    "    return {\"error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16436f6f-3f0f-4a7b-a524-bf4206f2fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GRU': {'Probability': array([[0.4452046]], dtype=float32), 'Classification': 'false'}, 'LR': {'Probability': 0.5018438824981267, 'Classification': 'true'}, 'DT': {'Probability': array([[0., 1.]]), 'Classification': 'true'}, 'RF': {'Probability': array([[0.43, 0.57]]), 'Classification': 'true'}}\n",
      "WARNING:tensorflow:From /tmp/ipykernel_15164/20130879.py:3: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Found 3733346_1 in file ../Kepler/TFRecords/train-00004-of-00008\n",
      "{'GRU': {'Probability': array([[0.2680739]], dtype=float32), 'Classification': 'false'}, 'LR': {'Probability': 0.5096319572817811, 'Classification': 'true'}, 'DT': {'Probability': array([[1., 0.]]), 'Classification': 'true'}, 'RF': {'Probability': array([[0.72, 0.28]]), 'Classification': 'true'}}\n",
      "Found 3733346_1 in file ../Kepler/TFRecords/train-00004-of-00008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GRU': {'Probability': array([[0.4138532]], dtype=float32), 'Classification': 'false'}, 'LR': {'Probability': 0.552142351657521, 'Classification': 'true'}, 'DT': {'Probability': array([[1., 0.]]), 'Classification': 'true'}, 'RF': {'Probability': array([[0.57, 0.43]]), 'Classification': 'true'}}\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"KIC 3733346\", \"kaggle\", \"tsfresh\", [\"gru\", \"lr\", \"rf\"]))\n",
    "#print(predict(\"KIC 3733346\", \"kaggle\", \"lightkurve\", [\"gru\", \"lr\", \"rf\"]))\n",
    "print(predict(\"KIC 3733346\", \"kepler\", \"lightkurve\", [\"gru\", \"lr\", \"rf\"]))\n",
    "print(predict(\"KIC 3733346\", \"kepler\", \"tsfresh\", [\"gru\", \"lr\", \"rf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d2f40-ecc5-43e9-bbfb-f504832de383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
