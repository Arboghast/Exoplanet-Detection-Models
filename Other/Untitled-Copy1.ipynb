{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34803b56-e29e-4439-9fc8-49e08586f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import scipy\n",
    "import pandas\n",
    "import numpy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed61eea-0cea-42bf-95dc-cb2844439394",
   "metadata": {},
   "source": [
    "We want to obtain the data files for TCE DR24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660fc41a-730e-47e5-a865-76fc15459140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20367\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_rowid</th>\n",
       "      <th>kepid</th>\n",
       "      <th>tce_plnt_num</th>\n",
       "      <th>tce_period</th>\n",
       "      <th>tce_period_err</th>\n",
       "      <th>tce_time0bk</th>\n",
       "      <th>tce_time0bk_err</th>\n",
       "      <th>tce_duration</th>\n",
       "      <th>tce_duration_err</th>\n",
       "      <th>av_training_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1162345</td>\n",
       "      <td>2</td>\n",
       "      <td>0.831850</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>132.227</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>2.392</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>AFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1292087</td>\n",
       "      <td>2</td>\n",
       "      <td>1.095240</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>132.133</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>2.122</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1293031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.719273</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>132.227</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>1.521</td>\n",
       "      <td>0.3183</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1162345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.831833</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>131.919</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>2.181</td>\n",
       "      <td>1.2110</td>\n",
       "      <td>AFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1164109</td>\n",
       "      <td>1</td>\n",
       "      <td>622.408000</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>162.256</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>12.010</td>\n",
       "      <td>1.8430</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_rowid    kepid  tce_plnt_num  tce_period  tce_period_err  tce_time0bk  \\\n",
       "0          1  1162345             2    0.831850        0.000067      132.227   \n",
       "1          2  1292087             2    1.095240        0.000010      132.133   \n",
       "2          3  1293031             2    0.719273        0.000014      132.227   \n",
       "3          4  1162345             3    0.831833        0.000009      131.919   \n",
       "4          5  1164109             1  622.408000        0.008547      162.256   \n",
       "\n",
       "   tce_time0bk_err  tce_duration  tce_duration_err av_training_set  \n",
       "0         0.035197         2.392           21.0000             AFP  \n",
       "1         0.002685         2.122            0.4755             UNK  \n",
       "2         0.002786         1.521            0.3183             UNK  \n",
       "3         0.002209         2.181            1.2110             AFP  \n",
       "4         0.009840        12.010            1.8430             UNK  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob(\"Kepler_TCE_DV_DR24/*.tbl\")\n",
    "print(len(filenames)) #20,367 rows!\n",
    "\n",
    "metadata = pandas.read_csv(\"q1_q17_dr24_tce.csv\", sep= ',', header=17)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543171f-6c65-4705-a5c6-ea80954b9b27",
   "metadata": {},
   "source": [
    "Now we want to cross reference out lightcurve files with the metadata table.\n",
    "We care more about false negatives than positives. we keep track of ids relative to the filenames order so that we can derive a filename from a kepler id (implicit mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080128a8-2812-4b2a-83fd-669f95a6faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idFromPath(path):\n",
    "    #print(re.match(r'/d{9}', path), path)\n",
    "    \n",
    "    kep_id = path[23:32] #extract the kepler id\n",
    "    plnt_num = path[49:51] #extract plnt num\n",
    "    kep_id = int(kep_id.lstrip(\"0\")) #remove leading zeros\n",
    "    plnt_num = int(plnt_num.lstrip(\"0\"))\n",
    "    \n",
    "    #print(\"plnt:\", plnt_num)\n",
    "    #print(\"kid:\", kep_id)\n",
    "    \n",
    "    kep_id = kep_id * 10 + plnt_num # combine into one unique identifier\n",
    "    #print(\"combined:\", kep_id)\n",
    "    return kep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d4ac66-68c6-4151-92d0-856d499c68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_logs = []\n",
    "labels = metadata[\"av_training_set\"]\n",
    "\n",
    "#we want to treat lightcurves from the same star on different planets as distinct\n",
    "kid = metadata[\"kepid\"].to_numpy()\n",
    "plnt_num = metadata[\"tce_plnt_num\"].to_numpy()\n",
    "for index in range(len(kid)):\n",
    "    new_id = kid[index] * 10 + plnt_num[index] # shift to left and add planet num\n",
    "    id_logs.append(new_id)\n",
    "    \n",
    "id_logs = numpy.array(id_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b38459-7e4c-4dff-b21a-f0b83e984543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_missing_time(time):\n",
    "  cadence_no = np.arange(len(time))\n",
    "  is_finite = np.isfinite(time)\n",
    "  num_finite = np.sum(is_finite)\n",
    "\n",
    "  interpolate_fn = scipy.interpolate.interp1d(\n",
    "      cadence_no[is_finite],\n",
    "      time[is_finite],\n",
    "      copy=False,\n",
    "      bounds_error=False,\n",
    "      fill_value=\"extrapolate\",\n",
    "      assume_sorted=True)\n",
    "\n",
    "  return interpolate_fn(cadence_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a992d91-b661-4b9d-9bc8-a9406e249f46",
   "metadata": {},
   "source": [
    "We see that there can be multiple files for a given id, not every file is the same size, some are segmented into multiple. We need to create a way to merge the files if there are many. \n",
    "\n",
    "Use a hashset to prevent duplicate ids from triggering, find all duplicate kepler ids and amalgamate them into a single lightcurve.\n",
    "\n",
    "Note: stars with multiple planets will have full light curves for each exoplanet. One soluton would be to treat each of these lightcurves as independent of each other.\n",
    "\n",
    "Safe to assume a majority of these lightcurves are all full length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e86bd0c5-a40e-451a-a739-328185120f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e+20\n",
      "<class 'numpy.ndarray'> <class 'numpy.float64'>\n",
      "update:  0 out of  20367\n",
      "1e+20\n",
      "<class 'numpy.ndarray'> <class 'numpy.float64'>\n",
      "1e+20\n",
      "<class 'numpy.ndarray'> <class 'numpy.float64'>\n",
      "1e+20\n",
      "<class 'numpy.ndarray'> <class 'numpy.float64'>\n",
      "1e+20\n",
      "<class 'numpy.ndarray'> <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "flux_data = [] #2d\n",
    "time_data = [] #time intervals - 1d\n",
    "used_files = []\n",
    "\n",
    "for index, path in enumerate(filenames):\n",
    "    \n",
    "    kep_id = idFromPath(path)\n",
    "    metadata_row = numpy.array(numpy.where(kep_id == id_logs)).flatten()[0]\n",
    "    \n",
    "    #print(labels[metadata_row] )\n",
    "    #ignore all UNK light curves\n",
    "    if( (kep_id in id_logs) and (labels[metadata_row] != 'UNK' ) ): #and (kep_id == 7100673)\n",
    "        \n",
    "        #rows tested to be always less than or equal to size 1, can assume not 0 aswell \n",
    "        data_table = Table.read(path, format='ipac')\n",
    "\n",
    "        if(len(time_data) == 0):\n",
    "            time_data = data_table['TIME'] #71427 time points\n",
    "            \n",
    "        print(data_table['INIT_FLUX_PL'].fill_value)\n",
    "        flux = data_table['INIT_FLUX_PL'].filled()\n",
    "        print(type(flux.data), type(flux[0]))\n",
    "\n",
    "        flux_data.append(flux)\n",
    "        used_files.append(kep_id)\n",
    "        \n",
    "        #plt.plot(time, flux, \".\")\n",
    "    \n",
    "    if(kep_id % 11 == 0):\n",
    "        break\n",
    "        \n",
    "    if(index % 100 == 0):\n",
    "        print(\"update: \", index, \"out of \", len(filenames))\n",
    "\n",
    "dataset = pandas.DataFrame(flux_data, columns = time_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e55630-bcbf-408e-aa23-dda77e8064cb",
   "metadata": {},
   "source": [
    "TODO: incorporate the planet numbers column from the csv and the planet number encoded in the file name. Once you get that working, I guess we can just make the dataset first and make separate logic for all the preprocessing.\n",
    "\n",
    "Add metadata to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7daaf754-5859-48fb-93eb-a051a9e37333",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['kepid'] = used_files\n",
    "\n",
    "#print(dataset['kepid'])\n",
    "metadata['new_id'] = id_logs\n",
    "\n",
    "#merge datasets based on new key\n",
    "dfinal = dataset.merge(metadata, how='inner', left_on='kepid', right_on='new_id')\n",
    "    \n",
    "#binaryzation\n",
    "mapping = {\"AFP\": 0, \"NTP\": 0, \"PC\": 1}\n",
    "dfinal[\"av_training_set\"] = dfinal[\"av_training_set\"].map(mapping)\n",
    "#print(dfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1ec2d4-dba2-41b5-a5cc-05a50b809890",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal.to_pickle(\"./kepler_dataset.pkl\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
